{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNIwe5N7s0e_"
   },
   "source": [
    "# Real-world Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_BG63Tpg8ep_"
   },
   "source": [
    "In this project, you will apply the skills you acquired in the course to gather and wrangle real-world data with two datasets of your choice.\n",
    "\n",
    "You will retrieve and extract the data, assess the data programmatically and visually, accross elements of data quality and structure, and implement a cleaning strategy for the data. You will then store the updated data into your selected database/data store, combine the data, and answer a research question with the datasets.\n",
    "\n",
    "Throughout the process, you are expected to:\n",
    "\n",
    "1. Explain your decisions towards methods used for gathering, assessing, cleaning, storing, and answering the research question\n",
    "2. Write code comments so your code is more readable\n",
    "\n",
    "Before you start, install the some of the required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install kaggle==1.6.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --target=/workspace ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDYDkH-Zs7Nn"
   },
   "source": [
    "## 1. Gather data\n",
    "\n",
    "In this section, you will extract data using two different data gathering methods and combine the data. Use at least two different types of data-gathering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbN7z7rcuqpO"
   },
   "source": [
    "### **1.1.** Problem Statement\n",
    "In 2-4 sentences, explain the kind of problem you want to look at and the datasets you will be wrangling for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi6swhjSYqu2"
   },
   "source": [
    "Finding the right datasets can be time-consuming. Here we provide you with a list of websites to start with. But we encourage you to explore more websites and find the data that interests you.\n",
    "\n",
    "* Google Dataset Search https://datasetsearch.research.google.com/\n",
    "* The U.S. Governmentâ€™s open data https://data.gov/\n",
    "* UCI Machine Learning Repository https://archive.ics.uci.edu/ml/index.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8AQfBAdUypMm"
   },
   "source": [
    "### **1.2.** Gather at least two datasets using two different data gathering methods\n",
    "\n",
    "List of data gathering methods:\n",
    "\n",
    "- Download data manually\n",
    "- Programmatically downloading files\n",
    "- Gather data by accessing APIs\n",
    "- Gather and extract data from HTML files using BeautifulSoup\n",
    "- Extract data from a SQL database\n",
    "\n",
    "Each dataset must have at least two variables, and have greater than 500 data samples within each dataset.\n",
    "\n",
    "For each dataset, briefly describe why you picked the dataset and the gathering method (2-3 full sentences), including the names and significance of the variables in the dataset. Show your work (e.g., if using an API to download the data, please include a snippet of your code). \n",
    "\n",
    "Load the dataset programmtically into this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e6gS0wL1KTu"
   },
   "source": [
    "#### **Dataset 1**: Infrastructure Damaged\n",
    "\n",
    "Type: JSON File\n",
    "\n",
    "Method: The data was gathered using the \"Programmatically downloading files\" method from https://github.com/TechForPalestine/palestine-datasets/tree/main github repository.\n",
    "\n",
    "Dataset variables:\n",
    "\n",
    "*   *report_date* : The date of the record\n",
    "*   *civic_buildings_ext_destroyed*\n",
    "*   *civic_buildings_destroyed* \n",
    "'educational_buildings_ext_destroyed',\n",
    "       'educational_buildings_ext_damaged', 'educational_buildings_destroyed',\n",
    "       'educational_buildings_damaged',\n",
    "       'places_of_worship_ext_mosques_destroyed',\n",
    "       'places_of_worship_ext_mosques_damaged',\n",
    "       'places_of_worship_ext_churches_destroyed',\n",
    "       'places_of_worship_mosques_destroyed',\n",
    "       'places_of_worship_mosques_damaged',\n",
    "       'places_of_worship_churches_destroyed', 'residential_ext_destroyed',\n",
    "       'residential_destroyed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "Su8E0uLuYkHU"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>civic_buildings</th>\n",
       "      <th>educational_buildings</th>\n",
       "      <th>places_of_worship</th>\n",
       "      <th>residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>{'ext_destroyed': 5}</td>\n",
       "      <td>{'ext_destroyed': 1, 'ext_damaged': 15}</td>\n",
       "      <td>{'ext_mosques_destroyed': 2, 'ext_mosques_dama...</td>\n",
       "      <td>{'ext_destroyed': 80}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>{'ext_destroyed': 11}</td>\n",
       "      <td>{'ext_destroyed': 1, 'ext_damaged': 30}</td>\n",
       "      <td>{'ext_mosques_destroyed': 4, 'ext_mosques_dama...</td>\n",
       "      <td>{'destroyed': 159, 'ext_destroyed': 159}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>{'ext_destroyed': 16}</td>\n",
       "      <td>{'ext_destroyed': 2, 'ext_damaged': 45}</td>\n",
       "      <td>{'ext_mosques_destroyed': 6, 'ext_mosques_dama...</td>\n",
       "      <td>{'destroyed': 790, 'ext_destroyed': 790}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>{'ext_destroyed': 22}</td>\n",
       "      <td>{'ext_destroyed': 2, 'ext_damaged': 60}</td>\n",
       "      <td>{'ext_mosques_destroyed': 8, 'ext_mosques_dama...</td>\n",
       "      <td>{'destroyed': 1009, 'ext_destroyed': 1009}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>{'destroyed': 27, 'ext_destroyed': 27}</td>\n",
       "      <td>{'destroyed': 3, 'ext_destroyed': 3, 'damaged'...</td>\n",
       "      <td>{'mosques_destroyed': 10, 'ext_mosques_destroy...</td>\n",
       "      <td>{'destroyed': 2835, 'ext_destroyed': 2835}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date                         civic_buildings  \\\n",
       "0  2023-10-07                    {'ext_destroyed': 5}   \n",
       "1  2023-10-08                   {'ext_destroyed': 11}   \n",
       "2  2023-10-09                   {'ext_destroyed': 16}   \n",
       "3  2023-10-10                   {'ext_destroyed': 22}   \n",
       "4  2023-10-11  {'destroyed': 27, 'ext_destroyed': 27}   \n",
       "\n",
       "                               educational_buildings  \\\n",
       "0            {'ext_destroyed': 1, 'ext_damaged': 15}   \n",
       "1            {'ext_destroyed': 1, 'ext_damaged': 30}   \n",
       "2            {'ext_destroyed': 2, 'ext_damaged': 45}   \n",
       "3            {'ext_destroyed': 2, 'ext_damaged': 60}   \n",
       "4  {'destroyed': 3, 'ext_destroyed': 3, 'damaged'...   \n",
       "\n",
       "                                   places_of_worship  \\\n",
       "0  {'ext_mosques_destroyed': 2, 'ext_mosques_dama...   \n",
       "1  {'ext_mosques_destroyed': 4, 'ext_mosques_dama...   \n",
       "2  {'ext_mosques_destroyed': 6, 'ext_mosques_dama...   \n",
       "3  {'ext_mosques_destroyed': 8, 'ext_mosques_dama...   \n",
       "4  {'mosques_destroyed': 10, 'ext_mosques_destroy...   \n",
       "\n",
       "                                  residential  \n",
       "0                       {'ext_destroyed': 80}  \n",
       "1    {'destroyed': 159, 'ext_destroyed': 159}  \n",
       "2    {'destroyed': 790, 'ext_destroyed': 790}  \n",
       "3  {'destroyed': 1009, 'ext_destroyed': 1009}  \n",
       "4  {'destroyed': 2835, 'ext_destroyed': 2835}  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Gather the data using the \"Programmatically downloading files\" method from https://github.com/\n",
    "nfrastructure_damaged_url =\"https://raw.githubusercontent.com/TechForPalestine/palestine-datasets/main/infrastructure-damaged.json\"\n",
    "nfrastructure_damaged_df = pd.read_json(nfrastructure_damaged_url)\n",
    "nfrastructure_damaged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report_date</th>\n",
       "      <th>civic_buildings_ext_destroyed</th>\n",
       "      <th>civic_buildings_destroyed</th>\n",
       "      <th>educational_buildings_ext_destroyed</th>\n",
       "      <th>educational_buildings_ext_damaged</th>\n",
       "      <th>educational_buildings_destroyed</th>\n",
       "      <th>educational_buildings_damaged</th>\n",
       "      <th>places_of_worship_ext_mosques_destroyed</th>\n",
       "      <th>places_of_worship_ext_mosques_damaged</th>\n",
       "      <th>places_of_worship_ext_churches_destroyed</th>\n",
       "      <th>places_of_worship_mosques_destroyed</th>\n",
       "      <th>places_of_worship_mosques_damaged</th>\n",
       "      <th>places_of_worship_churches_destroyed</th>\n",
       "      <th>residential_ext_destroyed</th>\n",
       "      <th>residential_destroyed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-07</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-08</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-09</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>790</td>\n",
       "      <td>790.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-10</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1009</td>\n",
       "      <td>1009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-11</td>\n",
       "      <td>27</td>\n",
       "      <td>27.0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2835</td>\n",
       "      <td>2835.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  report_date  civic_buildings_ext_destroyed  civic_buildings_destroyed  \\\n",
       "0  2023-10-07                              5                        NaN   \n",
       "1  2023-10-08                             11                        NaN   \n",
       "2  2023-10-09                             16                        NaN   \n",
       "3  2023-10-10                             22                        NaN   \n",
       "4  2023-10-11                             27                       27.0   \n",
       "\n",
       "   educational_buildings_ext_destroyed  educational_buildings_ext_damaged  \\\n",
       "0                                    1                                 15   \n",
       "1                                    1                                 30   \n",
       "2                                    2                                 45   \n",
       "3                                    2                                 60   \n",
       "4                                    3                                 75   \n",
       "\n",
       "   educational_buildings_destroyed  educational_buildings_damaged  \\\n",
       "0                              NaN                            NaN   \n",
       "1                              NaN                            NaN   \n",
       "2                              NaN                            NaN   \n",
       "3                              NaN                            NaN   \n",
       "4                              3.0                           75.0   \n",
       "\n",
       "   places_of_worship_ext_mosques_destroyed  \\\n",
       "0                                        2   \n",
       "1                                        4   \n",
       "2                                        6   \n",
       "3                                        8   \n",
       "4                                       10   \n",
       "\n",
       "   places_of_worship_ext_mosques_damaged  \\\n",
       "0                                      4   \n",
       "1                                      8   \n",
       "2                                     12   \n",
       "3                                     17   \n",
       "4                                     21   \n",
       "\n",
       "   places_of_worship_ext_churches_destroyed  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "\n",
       "   places_of_worship_mosques_destroyed  places_of_worship_mosques_damaged  \\\n",
       "0                                  NaN                                NaN   \n",
       "1                                  NaN                                NaN   \n",
       "2                                  NaN                                NaN   \n",
       "3                                  NaN                                NaN   \n",
       "4                                 10.0                                NaN   \n",
       "\n",
       "   places_of_worship_churches_destroyed  residential_ext_destroyed  \\\n",
       "0                                   NaN                         80   \n",
       "1                                   NaN                        159   \n",
       "2                                   NaN                        790   \n",
       "3                                   NaN                       1009   \n",
       "4                                   NaN                       2835   \n",
       "\n",
       "   residential_destroyed  \n",
       "0                    NaN  \n",
       "1                  159.0  \n",
       "2                  790.0  \n",
       "3                 1009.0  \n",
       "4                 2835.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nfrastructure_damaged_normalized = pd.DataFrame()\n",
    "nfrastructure_damaged_normalized['report_date'] = nfrastructure_damaged_df['report_date']\n",
    "\n",
    "for col in nfrastructure_damaged_df.columns:    \n",
    "    normalized_data = pd.json_normalize(nfrastructure_damaged_df[col])\n",
    "    normalized_data.columns = [f\"{col}_{subcol}\" for subcol in normalized_data.columns]  # Rename columns with prefix\n",
    "    nfrastructure_damaged_normalized = pd.concat([nfrastructure_damaged_normalized, normalized_data], axis=1)\n",
    "\n",
    "nfrastructure_damaged_normalized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hoUjq1tPzz7P"
   },
   "source": [
    "#### **Dataset 2**: Casualties daily\n",
    "\n",
    "Type: JSON file\n",
    "\n",
    "Method: The data was gathered using the \"Download data manually\" method from https://github.com/TechForPalestine/palestine-datasets/blob/main/casualties_daily.json repository source.\n",
    "\n",
    "Dataset variables:\n",
    "\n",
    "*   *Variable 1 FILL IN* (e.g., H_MEAN: Mean hourly wage)\n",
    "*   *Variable 2 FILL IN*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6zT0QxRyYmm7"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File casualties_daily.json does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## 2nd data gathering was manually downloaded from https://github.com/TechForPal\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m daily_casualties \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_json\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcasualties_daily.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m daily_casualties\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\SS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\json\\_json.py:791\u001b[0m, in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtable\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    789\u001b[0m     convert_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 791\u001b[0m json_reader \u001b[38;5;241m=\u001b[39m \u001b[43mJsonReader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvert_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_default_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_default_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecise_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecise_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_unit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    807\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding_errors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    810\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize:\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m json_reader\n",
      "File \u001b[1;32mc:\\Users\\SS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\json\\_json.py:904\u001b[0m, in \u001b[0;36mJsonReader.__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, lines, chunksize, compression, nrows, storage_options, encoding_errors, dtype_backend, engine)\u001b[0m\n\u001b[0;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m filepath_or_buffer\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mujson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data_from_filepath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    905\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(data)\n",
      "File \u001b[1;32mc:\\Users\\SS\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\json\\_json.py:960\u001b[0m, in \u001b[0;36mJsonReader._get_data_from_filepath\u001b[1;34m(self, filepath_or_buffer)\u001b[0m\n\u001b[0;32m    952\u001b[0m     filepath_or_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m    955\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m filepath_or_buffer\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m file_exists(filepath_or_buffer)\n\u001b[0;32m    959\u001b[0m ):\n\u001b[1;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_or_buffer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    961\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    963\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing literal json to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mread_json\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwill be removed in a future version. To read from a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    967\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    968\u001b[0m     )\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File casualties_daily.json does not exist"
     ]
    }
   ],
   "source": [
    "## 2nd data gathering was manually downloaded from https://github.com/TechForPal\n",
    "daily_casualties = pd.read_json('./data/casualties_daily.json')\n",
    "daily_casualties.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional data storing step: You may save your raw dataset files to the local data store before moving to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optional: store the raw data in your local data store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwSWIVmotLgV"
   },
   "source": [
    "## 2. Assess data\n",
    "\n",
    "Assess the data according to data quality and tidiness metrics using the report below.\n",
    "\n",
    "List **two** data quality issues and **two** tidiness issues. Assess each data issue visually **and** programmatically, then briefly describe the issue you find.  **Make sure you include justifications for the methods you use for the assessment.**\n",
    "\n",
    "\n",
    "Now that we have gathered the datasets, let's assess the dataset for data quality and structural issues.\n",
    "\n",
    "Here's a list of the data quality attributes we covered in the course for your reference:\n",
    "\n",
    "    Completeness\n",
    "    Validity\n",
    "    Accuracy\n",
    "    Consistency\n",
    "    Uniqueness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "adaK2iPNzVu4"
   },
   "source": [
    "### Quality Issue 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpW59kh-zl8d"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-qfcocStzsKg"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Be77N4I1AmE"
   },
   "source": [
    "### Quality Issue 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMhHyiyLM2I3"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnviRCUI-bb7"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXhGiYyiwwKN"
   },
   "source": [
    "### Tidiness Issue 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fleC5rORI0Xl"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BTuQw7Rbsio4"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ffMoRGSwzYj"
   },
   "source": [
    "### Tidiness Issue 2: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XUpeoqokw5Qt"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe visually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c8JK4DoXxtFA"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Inspecting the dataframe programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue and justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6gmLnBttpCh"
   },
   "source": [
    "## 3. Clean data\n",
    "It's time to address the issues found during assessment to clean and polish your data.\n",
    "\n",
    "Clean the data to solve the 4 issues corresponding to data quality and tidiness found in the assessing step. **Make sure you include justifications for your cleaning decisions.**\n",
    "\n",
    "After the cleaning for each issue, please use **either** the visually or programatical method to validate the cleaning was succesful.\n",
    "\n",
    "At this stage, you are also expected to remove variables that are unnecessary for your analysis and combine your datasets. Depending on your datasets, you may choose to perform variable combination and elimination before or after the cleaning stage. Your dataset must have **at least** 4 variables after combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FILL IN - Make copies of the datasets to ensure the raw dataframes \n",
    "# are not impacted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmFhN52Yyn3l"
   },
   "source": [
    "### **Quality Issue 1: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9UejDWrNMW4a"
   },
   "outputs": [],
   "source": [
    "# FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oUBee-LPytkv"
   },
   "outputs": [],
   "source": [
    "# FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_DAUbJrymBL"
   },
   "source": [
    "### **Quality Issue 2: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Yfb-Yu5MTuE"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ionB2sRaMUmY"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIUrrfSNyOPR"
   },
   "source": [
    "### **Tidiness Issue 1: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fib0zAm333bn"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yhrnUGY_Nk8B"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o51Bt8kwyTzk"
   },
   "source": [
    "### **Tidiness Issue 2: FILL IN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7zW8O5yx4Y9O"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Apply the cleaning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6I_Sr7lxXi5"
   },
   "outputs": [],
   "source": [
    "#FILL IN - Validate the cleaning was successful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Justification: *FILL IN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Remove unnecessary variables and combine datasets**\n",
    "\n",
    "Depending on the datasets, you can also peform the combination before the cleaning steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FILL IN - Remove unnecessary variables and combine datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F42urHuzttjF"
   },
   "source": [
    "## 4. Update your data store\n",
    "Update your local database/data store with the cleaned data, following best practices for storing your cleaned data:\n",
    "\n",
    "- Must maintain different instances / versions of data (raw and cleaned data)\n",
    "- Must name the dataset files informatively\n",
    "- Ensure both the raw and cleaned data is saved to your database/data store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V3uay7EJUV_L"
   },
   "outputs": [],
   "source": [
    "#FILL IN - saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGy_yddGtzhM"
   },
   "source": [
    "## 5. Answer the research question\n",
    "\n",
    "### **5.1:** Define and answer the research question \n",
    "Going back to the problem statement in step 1, use the cleaned data to answer the question you raised. Produce **at least** two visualizations using the cleaned data and explain how they help you answer the question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjedE4s4ZkEd"
   },
   "source": [
    "*Research question:* FILL IN from answer to Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lkw3rW9kZmOm"
   },
   "outputs": [],
   "source": [
    "#Visual 1 - FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Answer to research question:* FILL IN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6fdK_8ZGZm9R"
   },
   "outputs": [],
   "source": [
    "#Visual 2 - FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5RgvMGUZoHn"
   },
   "source": [
    "*Answer to research question:* FILL IN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ezWXXZVj-TP"
   },
   "source": [
    "### **5.2:** Reflection\n",
    "In 2-4 sentences, if you had more time to complete the project, what actions would you take? For example, which data quality and structural issues would you look into further, and what research questions would you further explore?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB3RBDG5kFe1"
   },
   "source": [
    "*Answer:* FILL IN"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
